---
title: "R/Business - Insurance Fraud Detection"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,   
                      message = FALSE,
                      warning = FALSE)
```

## R Business - Insurance Fraud Detection I

Our goal at R Business is to encourage the use of R Studio in a varity of industries where it is current use has been underdevloped. One of these industries is insurance where Excel, VBA and SAS still seem to be the dominant forces. This tutorial is meant to show a simple example of what R Studio is capable of in an insurance related Use Case. Namely the detection of potential fraudulent activity. This is an extremely simplified data set and workflow, but the basic procedure remains the same even in more complex real world examples.

## Assumptions

This tutorial assumes some basic competency with [R Studio](https://rstudio.com/) and the [Random Forest](https://en.wikipedia.org/wiki/Random_forest) method. If you aren't familiar with these I would recommend you first read up n them in the links provided. 

## Load Libraries

The first step is to load all the libraries you will need during this example. We will need quite a lot of them in order to properly run this analysis. One of the main benefits of R Studio is the richness of high quality libraries for complex statistical methods.

```{r, warning=FALSE}
# Load Libraries
library(dplyr)
library(readr)
library(randomForest)
library(rfUtilities)
library(rsample)
library(ggplot2)
library(caret)
library(e1071)
library(skimr)
```

## Load Data

Then load the data and perform an initial check. This particular dataset if from [Kaggle](https://www.kaggle.com/buntyshah/auto-insurance-claims-data). I would recommend downloading it and putting it into your local directory.

```{r data, echo=FALSE}
#Loading and Discovery

# Load Data
data <- read_csv("insurance_claims.csv")

# First Look at Data
head(data)
```

## Inspect Data

Since everything seems fine we should dive a little deeper into it. Let's check data types and NAs. The "skim" function also provides a lot of insight.

```{r data, echo=FALSE}
# Check Types
sapply(data, class)

# Check for NAs 
data[!complete.cases(data),] #non found

# Summarize Data
skim(data)
```

## Data Wrangling

This part is where it gets (a little) tricky. If we had found any NAs we would have had to remove them at this point. The na.omit() function makes that very easy. Good data cleaning can be about 80% of the work in these projects, but luckliy we already have some very clean data. All we need to do here is convert some of the column types to more sensical formats.

```{r data, echo=FALSE}
#Data Wrangling
#data$fraud_reported[data$fraud_reported == 'Y']  <- 1
#data$fraud_reported[data$fraud_reported == 'N']  <- 0
data$fraud_reported <- as.integer(data$fraud_reported)
data$insured_zip <- as.character(data$insured_zip)
data$policy_bind_date <- as.Date(data$policy_bind_date, format = '%m/%d/%y')

# Check for amount of uniqe values
sapply(sapply(data, unique), length)
```
# Prepare Data for RF

Random Forest wont work if there are too many unique values in a factor, which is why we remove those above a certain threshhold. This is more art than science though. The Random Forest will give you a warning if you exceed certain limits.

```{r data, echo=FALSE}
# Drop obvious colimns
drops <- c('incident_location','policy_bind_date','incident_date','insured_occupation','insured_zip', 'policy_number')
data <- data[ , !(names(data) %in% drops)]

# turn into factors
data <- data %>% mutate_if(is.character, as.factor)
#data$fraud_reported <- as.factor(data$fraud_reported)
```

## Split Data

```{r data, echo=FALSE}

# For reproducability
set.seed(52)

# Split Data
data_split <- initial_split(data, prop = .7)
data_train <- training(data_split)
data_test  <- testing(data_split )
```

## Basic Implementation & Analysis

```{r data, echo=FALSE}
# Basic Implementation & Analysis

# default RF model
rf1 <- randomForest(
  formula = fraud_reported ~ .,
  data    = data_train)

# Model
rf1
```

# Check Results

```{r data, echo=FALSE}
# Plot tree
plot(rf1)

# Lowest MSE
which.min(rf1$mse)

# RMSE of this optimal random forest
# sqrt(rf1$mse[which.min(rf1$mse)])

#Variable Importance
rf1$importance
```

## RF Initial Validation


```{r data, echo=FALSE}
# Split down set further for validation set on training data

# create training and validation data 
data_split <- initial_split(data_train, .8)

# training data
data_train_v2 <- analysis(data_split)

# validation data
data_valid <- assessment(data_split)
x_test <- data_valid[setdiff(names(data_valid),"fraud_reported")]
y_test <- data_valid$fraud_reported

rf_oob_comp <- randomForest(
  formula = fraud_reported ~ .,
  data    = data_train_v2,
  xtest   = x_test,
  ytest   = y_test)

# extract OOB & validation errors
oob <- sqrt(rf_oob_comp$mse)
validation <- sqrt(rf_oob_comp$test$mse)

# compare error rates
tibble::tibble(
  `Out of Bag Error` = oob,
  `Test error` = validation,
  ntrees = 1:rf_oob_comp$ntree
) %>%
  gather(Metric, RMSE, -ntrees) %>%
  ggplot(aes(ntrees, RMSE, color = Metric)) +
  geom_line() +
  scale_y_continuous(labels = scales::dollar) +
  xlab("Number of trees")

```



## RF Tuning

```{r data, echo=FALSE}
# names of features
features <- setdiff(names(data_valid),"fraud_reported")

# tune Random Forest
rf2 <- tuneRF(
  x          = data_train[features],
  y          = data_train$fraud_reported,
  ntreeTry   = 500,
  mtryStart  = 5,
  stepFactor = 1.5,
  improve    = 0.01,
  trace      = TRUE      # to not show real-time progress 
)

# Try best version
rf2 <- randomForest(
  x          = data_train[features],
  y          = data_train$fraud_reported,
  data    = data_train,
  ntree = 500,
  mtry = 15
)
```


# Check results


```{r data, echo=FALSE}
rf2

# Plot tree
plot(rf2)

#Variable Importance
rf2$importance
```


## Predicting

```{r data, echo=FALSE}
# randomForest
pred_randomForest <- predict(rf2, data_test)
head(pred_randomForest)

# Make pred column
data_test$pred <- predict(rf2, data_test)
data_test$pred_final <- as.integer(ifelse(data_test$pred > 0.3 ,1 ,0))
                          
# Confusion Matrix
confusionMatrix(as.factor(data_test$fraud_reported), as.factor(data_test$pred_final))
```



